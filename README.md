"# AIAYN-transformer" 

ğŸ”¬ Description
Minimal, faithful implementation of the Transformer architecture introduced in "Attention Is All You Need" (Vaswani et al., 2017). This repository excludes modern modifications (e.g., pre-layer norm, relative positional encoding, etc.) to preserve the original design for research, benchmarking, and educational purposes. Implementation by Omar Ibrahim et al.

ğŸ“ Features
Encoder-decoder Transformer architecture

Scaled dot-product attention

Multi-head attention

Position-wise feedforward networks

Learned positional encoding

Masking for autoregressive decoding

No dependencies on modern Transformer wrappers or libraries

ğŸ“„ Reference
Vaswani et al., "Attention is All You Need", NeurIPS 2017
https://arxiv.org/abs/1706.03762

ğŸ›  Requirements
Python â‰¥ 3.8

PyTorch â‰¥ 1.10 

NumPy
